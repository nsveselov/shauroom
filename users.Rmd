```{r library}
library(tm)
library(RColorBrewer)
library(ggplot2)
library(wordcloud)
library(cluster)
library(igraph)
library(fpc)
library(tidyr)
library(dplyr)
library(stringr)
library(vkR)
library(devtools)
library(RCurl)
library(httr)
library(RJSONIO)
library(lubridate)
```


```{r загрузка функций}
#не запускайте полностью чанк, это плохая идея, долго оч
source_url("https://gist.githubusercontent.com/paulokopny/63daf8ca42f9d842b122/raw/bf7c8f9f6944b44e7c791cb66f4919bd762f4dc9/vk.R") 
vk <- get.vk.connector(code = "7f2ba74370408f5ca3", app = "karepin", debug = T)
users.get <- function(vk.get_data, user_ids, fields = "sex,bdate,city,country,home_town,education,universities,schools,counters,occupation,relation,personal") {
  method = "users.get"
  assert_that(!is.null(user_ids))
  assert_that(is.character(user_ids))
  assert_that(length(user_ids) == 1)
  assert_that(length(str_split(user_ids, pattern = ",")[[1]]) <= 15000)
  assert_that(is.character(fields))
  assert_that(length(fields) == 1)
  Sys.sleep(1)
  print("Getting data...")
  return(vk.get_data(method=method, user_ids = user_ids, fields = fields))
} #параметры fields можно менять (https://vk.com/dev/fields), правда список инфы,что там предлагают не особо радует
#переменные
full<-read.csv("~/shaverma_df_light.csv")
ids<-as.data.frame(full$reviewer_id)
ids<-as.data.frame(ids[!duplicated(ids),])
names(ids) <- c("id")
ids$id<- removePunctuation(as.character(ids$id))
ids$id<- as.character(ids$id)
```

```{r запрос ВК и оформление датафрейма по возвращенным данным}
user_ids<-"511515"
user_ids<-gsub(" ", "", user_ids, fixed = T)
json1<-users.get(vk,user_ids)
#этот запрос позволяет получить инфу до 400 человек, чтобы было больше, надо менять код, но как, я не разобрался (скрипт для большого количества ниже)
profiles = sapply(1:length(json), function(z){as.data.frame(t(unlist(json[[z]])))})
profiles = do.call(plyr::rbind.fill, profiles) 
profiles = as.data.frame(profiles, stringsAsFactors = FALSE) 

```

```{r собственно скрипт }

all<- NULL
for (q in 1:2){ #174 
  user_ids<-'1'
    for (i in 1:350) {
      
    user_ids<- paste(user_ids,',',as.character(ids[((q-1)*350+i),c('id')]))
    }
    user_ids<-gsub(" ", "", user_ids, fixed = T)
    json<-users.get(vk,user_ids)
    profiles = sapply(1:length(json), function(z){as.data.frame(t(unlist(json[[z]])))})
    profiles = do.call(plyr::rbind.fill, profiles) 
    profiles = as.data.frame(profiles, stringsAsFactors = FALSE) 
    new<- profiles
    all<-merge(all,new,all=T)
  all<-unique(all)
  
}

alle<-all
alle<- unique(all)
write.csv(all, "Users.csv")
triz<-all
vos<-all
sto<-all
us<-read.csv("~/sss/shauroom/users.csv")
class(a$uid)
us$uid<-as.numeric(us$uid)
```


```{r наброски кода для группировки пользователей/удобоваримости в общем}
members<-top_n(all,1000)
all$sex <- ifelse(all$sex==1, 'F', 'M')
sex <- table(na.omit(members$sex))

# данные для группировки по возрасту (не смотрел)
age_intervals <- c(16, 21, 26, 31, 36, 41)
age_names <- c('<16', '16-20', '21-25', '26-30', '31-35', '36-40', '40>')
age_bins = table(findInterval(na.pass(members$age), age_intervals))
names(age_bins) <- age_names
# посмотрим на данные
sex

```

```{r попытки поиска инфы по группам}
subs.get <- function(vk.get_data, user_ids, extended, fields = "id,name") {
  method = "users.getSubscriptions"
  assert_that(!is.null(user_ids))
  assert_that(is.character(user_ids))
  assert_that(length(user_ids) == 1)
  assert_that(length(str_split(user_ids, pattern = ",")[[1]]) <= 15000)
  assert_that(is.character(fields))
  assert_that(length(fields) == 1)
  Sys.sleep(1)
  print("Getting data...")
  return(vk.get_data(method=method, user_ids = user_ids, fields = fields))
} #параметры fields можно менять (https://vk.com/dev/fields), правда список инфы,что там предлагают не особо радует
user_ids<-'59138821,141155' #по такому же примеру нужно составить список id голосовавших

j<-users.get(vk,as.character(user_ids)) 
json<-users.get(vk,user_ids)
profiles = sapply(1:length(json), function(z){as.data.frame(t(unlist(json[[z]])))})
profiles = do.call(plyr::rbind.fill, profiles) 
profiles = as.data.frame(profiles, stringsAsFactors = FALSE) 
```

```{r just tryna}
#сотри пароль
source_url("https://gist.githubusercontent.com/paulokopny/63daf8ca42f9d842b122/raw/bf7c8f9f6944b44e7c791cb66f4919bd762f4dc9/vk.R")
vk <- get.vk.connector(code = "e43b1ea274c0171622", app = "karepin", debug = T) 
setAccessToken(access_token='69ca258bb19616bdd56ed531725746c8cb56ebf1a4b2fdbadedc260ef1a13adc7a4e325ee2d3fa38a5cae')
vkOAuth(5585217, 'groups', 'логинВК', 'пароль')
fromJSON(getURL('https://api.vk.com/method/users.getSubscriptions?user_id=10644545'))
user_id<-"10644545"


##########для долгого скрипта
user_id<-'21321'
url<- paste('https://api.vk.com/method/users.getSubscriptions?user_id=',user_id)
url<-gsub(" ", "", url, fixed = T)
json<-getURL(url)
new<-fromJSON(json)
a=c(user_id,new$response$groups$items)

###оставь
one<-as.data.frame(t(a))
two<-as.data.frame(t(a))
all<-merge(one,two,all=TRUE)
##########для долгого скрипта
groups=paste(new$response$groups$items, sep = ",")
user_id<-'21321'
url<- paste('https://api.vk.com/method/users.getSubscriptions?user_id=',user_id)
url<-gsub(" ", "", url, fixed = T)
json<-getURL(url)
new<-fromJSON(json)
a=c(user_id,paste(new$response$groups$items))
b<-paste(new$response$groups$items,sep = ",")

groupsone<-one
rownames()
groupsone<-paste(user_id,':')

for (i in 1:new$response$groups$count) {
      
    groupsone<- paste(groupsone,',',as.character(one[1,i]))
    } 
groupsone<-gsub(" ", "", groupsone, fixed = T)
a<-c(groupsone)
b<-c(groupstwo)
a<-as.data.frame(a)
names(a) <- c("g")
b<-as.data.frame(b)
names(b)<-c("g")
alll<-merge(a,b,all=T)
all<-separate(alll, col='g', into=c("uid","groups"), sep=":,")


```
```{r без мусора}
full<-read.csv("~/shaverma_df_light.csv")
ids<-as.data.frame(full$reviewer_id)
ids<-unique(ids)
names(ids) <- c("id")
ids$id<- removePunctuation(as.character(ids$id))
ids$id<- as.character(ids$id)
all<-alll
for (z in 1:3) {
  user_id=as.character(ids[z,1])
  url<- paste('https://api.vk.com/method/users.getSubscriptions?user_id=',user_id)
  url<-gsub(" ", "", url, fixed = T)
  json<-getURL(url)
  new<-fromJSON(json)
  a=c(new$response$groups$items)
  one<-as.data.frame(a)
  groupsone<-paste(user_id,':')
  for (i in 1:new$response$groups$count) {
      
    groupsone<- paste(groupsone,',',as.character(one[i,1]))
  } 
  groupsone<-gsub(" ", "", groupsone, fixed = T)
  a<-c(groupsone)
  b<-as.data.frame(a)
  alll<-separate(b, col='a', into=c("uid","groups"), sep=":,")
  all<-merge(all,alll,all=T)
  all<-unique(all)
}
```

